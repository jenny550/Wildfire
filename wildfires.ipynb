{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenny550/mit_futuremakers_create-a-thon_2023/blob/main/wildfires.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wildfire Image Detection"
      ],
      "metadata": {
        "id": "Zb7Nkk4uq3vC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipyleaflet  # module source: jupyter notebook map feature module: #https://ipyleaflet.readthedocs.io/en/latest/index.html\n",
        "!pip install ipinfo #source: https://github.com/ipinfo/python\n",
        "!pip install googlemaps"
      ],
      "metadata": {
        "id": "hHWUNGGb5z6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import os\n",
        "from google.colab import drive\n",
        "import ee\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "with open('/content/gdrive/My Drive/file.txt', 'w') as f:\n",
        "    f.write('content')"
      ],
      "metadata": {
        "id": "OjN2p5YN6g23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ee.Authenticate()\n",
        "ee.Initialize()\n",
        "#verification code: click link and accept account"
      ],
      "metadata": {
        "id": "3-NIpi6eizBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from geopy.geocoders import Nominatim\n",
        "\n",
        "#easiest way to get longitude and latitude from user. Inf ututre situations, ethics and user permission will be requested.\n",
        "\n",
        "\n",
        "app = Nominatim(user_agent=\"tutorial\")\n",
        "location = app.geocode(\"Massachusetts, United States\").raw\n",
        "lat, lng = location['lat'], location['lon']\n",
        "print(f\"\"\"\n",
        "     latitude: {lat}\n",
        "     longitude: {lng}\n",
        "      \"\"\")"
      ],
      "metadata": {
        "id": "DElLpfrRjYbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get map source: https://developers.google.com/earth-engine/tutorials/community/intro-to-python-api#get_a_static_map\n",
        "from ipyleaflet import Map, basemaps, basemap_to_tiles, Marker\n",
        "\n",
        "map = Map(\n",
        "          basemap = basemaps.Esri.WorldImagery,\n",
        "          center = [lat, lng],\n",
        "          zoom = 12,\n",
        "\n",
        "          )\n",
        "#map.add_layer(Marker(location=(long_lat)))\n",
        "\n",
        "map"
      ],
      "metadata": {
        "id": "UgumvEl8jMzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Architecture"
      ],
      "metadata": {
        "id": "nEbIKq1X7NzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#history =  model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
        "                  #   validation_data = #Enter Code ,\n",
        "                    # verbose=1)"
      ],
      "metadata": {
        "id": "th4ef9jM82qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading images into arrays\n",
        "\n",
        "train_fire_arr = [np.array( Image.open(f'/content/gdrive/MyDrive/WildFires_SureStart_Comp/training/fire/{x}').resize((128,128)) ) for x in os.listdir('/content/gdrive/MyDrive/WildFires_SureStart_Comp/training/fire')] #training fie imgs\n",
        "train_noFire_arr = [np.array(Image.open(f'/content/gdrive/MyDrive/WildFires_SureStart_Comp/training/nofire/{x}', mode='r').resize((128,128)) ) for x in os.listdir('/content/gdrive/MyDrive/WildFires_SureStart_Comp/training/nofire')] #training noFire imgs\n",
        "\n",
        "test_fire_arr = [np.array(Image.open(f'/content/gdrive/MyDrive/WildFires_SureStart_Comp/testing/fire/{x}', mode='r').resize((128,128)) ) for x in os.listdir('/content/gdrive/MyDrive/WildFires_SureStart_Comp/testing/fire')] #testing fire imgs\n",
        "test_noFire_arr = [np.array(Image.open(f'/content/gdrive/MyDrive/WildFires_SureStart_Comp/testing/noFire/{x}', mode='r').resize((128,128)) ) for x in os.listdir('/content/gdrive/MyDrive/WildFires_SureStart_Comp/testing/noFire')] #testing noFire imgs\n",
        "\n",
        "train = np.array(train_fire_arr + train_noFire_arr)\n",
        "print('train: fire length: ', len(train_fire_arr))\n",
        "print('train: noFire length: ', len(train_noFire_arr))\n",
        "print('train: fire + noFire length: ', len(train))\n",
        "\n",
        "test = np.array(test_fire_arr + test_noFire_arr)\n",
        "print('test: fire length: ', len(test_fire_arr))\n",
        "print('test: noFire length: ', len(test_noFire_arr))\n",
        "print('test: fire + noFire length: ', len(test))\n",
        "\n",
        "#print(train_fire_arr[0])\n",
        "#plt.imshow(train[1800])\n",
        "\n",
        "test[0].shape # each img is 250 x 250"
      ],
      "metadata": {
        "id": "bLydEHJ_iHv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train = images of fires\n",
        "#labels = {0: no fire, 1.0: fire}\n",
        "#y_train = all labels of fire, hint: {1.0}\n",
        "\n",
        "x_train, y_train = train, np.concatenate((np.ones(len(train_fire_arr)), np.zeros(len(train_noFire_arr))), axis = 0)\n",
        "x_test, y_test = test, np.concatenate((np.ones(len(test_fire_arr)), np.zeros(len(test_noFire_arr))), axis = 0)\n",
        "idx = -1\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "print(y_train[idx])\n",
        "print(x_train[idx])\n",
        "plt.imshow(x_train[idx])"
      ],
      "metadata": {
        "id": "bEIzz5VMk43-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf `find -type d -name .ipynb_checkpoints`"
      ],
      "metadata": {
        "id": "ZiofOSNE7lCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = ImageDataGenerator(rescale=1/255) # conguring training dataset frame, pixel / 255\n",
        "test = ImageDataGenerator(rescale=1/255) # conguring training dataset frame, pixel / 255\n",
        "\n",
        "train_dataset = train.flow_from_directory(\"/content/gdrive/MyDrive/WildFires_SureStart_Comp/training\",\n",
        "                                          target_size=(128,128),\n",
        "                                          batch_size = 32,\n",
        "                                          class_mode='binary') # further configuring dataset frame, already loaded with image contents\n",
        "\n",
        "test_dataset = test.flow_from_directory(\"/content/gdrive/MyDrive/WildFires_SureStart_Comp/testing\",\n",
        "                                          target_size=(128,128),\n",
        "                                          batch_size =32,\n",
        "                                          class_mode = 'binary')  # further configuring dataset frame, already loaded with image contents"
      ],
      "metadata": {
        "id": "508y_8S_vdRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.class_indices #print out class indicies: 0 for {fire}, 1 for {no fire }"
      ],
      "metadata": {
        "id": "8L7pAJMkzTKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nf72VxOYGN41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#strides increased for speed\n",
        "stride = (2,2)\n",
        "\n",
        "#padding added to ensure edges of inputs are also processed\n",
        "padd = 'same'\n",
        "\n",
        "#model source: https://www.kaggle.com/code/andersonblanco/forest-fire-detection-using-cnn/edit\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(128,128,3), strides = stride, padding = padd))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "model.add(keras.layers.Conv2D(64,(3,3),activation='relu', strides = stride, padding = padd))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "model.add(keras.layers.Conv2D(128,(3,3),activation='relu', strides = stride, padding = padd))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "#model.add(keras.layers.Conv2D(128,(3,3),activation='relu', strides = stride, padding = padd)) #removing these layers, caused the model to increase accuracy and speed. As we saw these layers as uneccessarry.\n",
        "#model.add(keras.layers.MaxPool2D(2,2))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(512,activation='relu'))\n",
        "model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "IvxT1L7z7dSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing filters: weights\n",
        "\n",
        "filters, biases = model.layers[0].get_weights()\n",
        "min, max = filters.min(), filters.max()\n",
        "filters = (filters - min) / (filters - max)\n",
        "\n",
        "n_filters, ix = 6,1\n",
        "fig, ax = plt.subplots(n_filters, 3, figsize=(10,10))\n",
        "for i in range(n_filters):\n",
        "  f = filters[:,:,0,i]\n",
        "\n",
        "  for j in range(3):\n",
        "    ax[i,j].imshow(f[:,:])\n",
        "    ix += 1"
      ],
      "metadata": {
        "id": "zjzdaRSxLNYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display first image in x_test\n",
        "plt.imshow(x_test[0])\n"
      ],
      "metadata": {
        "id": "jW_Viw0TQPdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature maps: input looks after applying filters(weights)\n",
        "\n",
        "#refining model to output after first layer:\n",
        "x_model = keras.models.Sequential(model.get_layer(index = 0))\n",
        "featureMaps = x_model.predict(x_test)\n",
        "ix = 1\n",
        "fig, ax = plt.subplots(8,4, figsize = (10,10))\n",
        "\n",
        "for i in range(8):\n",
        "  for j in range(4):\n",
        "    ax[i, j].imshow(featureMaps[0, :, :, ix-1])\n",
        "    ix += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "77dyCsX8OmX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "17uZt5k_LMbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y_train.resize(1832, 1)\n",
        "#print(y_train[2])\n",
        "fitted = model.fit(train_dataset, validation_data=test_dataset, epochs = 10)"
      ],
      "metadata": {
        "id": "eyT1M9lSwnKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_hoS5xLnk_O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction examples:\n",
        "# 0 == Fire, 1 == No Fire\n",
        "fires = test_fire_arr[0:8]\n",
        "noFires = test_noFire_arr[8:16]\n",
        "totals = fires + noFires\n",
        "\n",
        "idx = 0\n",
        "fig, ax = plt.subplots(4,4, figsize = (10,12), squeeze=False )\n",
        "\n",
        "for row in range(4):\n",
        "  for column in range(4):\n",
        "    a = ax[row, column]\n",
        "    X = np.expand_dims(totals[idx], axis = 0)\n",
        "    predVal = model.predict(X)\n",
        "    a.imshow(totals[idx])\n",
        "    if predVal == 1:\n",
        "      a.set_title('No Fire', fontsize = 15)\n",
        "    else:\n",
        "      a.set_title('Fire', fontsize = 15)\n",
        "    idx += 1\n"
      ],
      "metadata": {
        "id": "avmEcrbJKHzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training vs testing loss and accuracy\n",
        "plt.plot(fitted.history['accuracy'], label='accuracy')\n",
        "plt.plot(fitted.history['val_loss'], label='val_loss')\n",
        "plt.plot(fitted.history['loss'], label='loss')\n",
        "plt.legend()\n",
        "\n",
        "#the graph shows the"
      ],
      "metadata": {
        "id": "_FKqXpucJvjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy plotting\n",
        "plt.plot(fitted.history['accuracy'], label='accuracy')\n",
        "plt.plot(fitted.history['val_accuracy'], label='val_accuracy')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "T-t9SV78t4yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ikolm3-uDCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions\n",
        "def predict(img):\n",
        "  X = np.expand_dims(img, axis = 0)\n",
        "  predVal = model.predict(X)\n",
        "  print(predVal)\n",
        "  plt.imshow(img)\n",
        "\n",
        "\n",
        "  if predVal == 1:\n",
        "    plt.xlabel('No Fire', fontsize = 34)\n",
        "  else:\n",
        "    plt.xlabel('Fire', fontsize = 34)"
      ],
      "metadata": {
        "id": "JqlcxJo0BjWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_fire_arr\n",
        "#test_noFire_arr\n",
        "predict(test_fire_arr[-15])"
      ],
      "metadata": {
        "id": "tQ7ImBR1Gf79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing activation:\n",
        "def visualize_activation(model,activations,activation_model):\n",
        "  layer_names = []\n",
        "  for layer in model.layers[0:9]:\n",
        "      layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n",
        "\n",
        "  images_per_row = 16\n",
        "\n",
        "  for layer_name, layer_activation in zip(layer_names, activations):       # Displays the feature maps\n",
        "      n_features = layer_activation.shape[-1]                              # Number of features in the feature map\n",
        "      size = layer_activation.shape[1]                                     # The feature map has shape (1, size, size, n_features).\n",
        "      n_cols = n_features // images_per_row                                # Tiles the activation channels in this matrix\n",
        "      display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "      for col in range(n_cols):                                            # Tiles each filter into a big horizontal grid\n",
        "          for row in range(images_per_row):\n",
        "              channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
        "              channel_image -= channel_image.mean()                        # Post-processes the feature to make it visually palatable\n",
        "              channel_image /= channel_image.std()\n",
        "              channel_image *= 64\n",
        "              channel_image += 128\n",
        "              channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "              display_grid[col * size : (col + 1) * size,row * size : (row + 1) * size] = channel_image\n",
        "      scale = 1. / size\n",
        "      plt.figure(figsize=(scale * display_grid.shape[1],\n",
        "                          scale * display_grid.shape[0]))\n",
        "      plt.title(layer_name)\n",
        "      plt.grid(False)\n",
        "      plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "\n",
        "\n",
        "img = np.array(test[0])\n",
        "img.resize(1, 128,128, 3)\n",
        "print(img.shape)\n",
        "# Storing outputs from each layer of the model\n",
        "layer_outputs = [layer.output for layer in model.layers[0:9]]\n",
        "\n",
        "activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "# Getting activations (predictions) of a test image\n",
        "activations  =  activation_model.predict(img)\n",
        "\n",
        "visualize_activation(model,activations,activation_model)"
      ],
      "metadata": {
        "id": "xxkU9PHcjeE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.array(test[0])\n",
        "img.resize(1, 128,128, 3)\n",
        "print(img.shape)"
      ],
      "metadata": {
        "id": "RxlPxYYPkgbU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}